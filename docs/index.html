<!DOCTYPE html> <html><head>
		<title>BLOGPOST</title>
		<base href="./">
		<meta id="root-path" root-path="./">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="notes - BLOGPOST">
		<meta property="og:title" content="BLOGPOST">
		<meta property="og:description" content="notes - BLOGPOST">
		<meta property="og:type" content="website">
		<meta property="og:url" content="blogpost.html">
		<meta property="og:image" content="pasted-image-20240306185652.png">
		<meta property="og:site_name" content="notes">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="preload" href="lib/styles/other-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/other-plugins.css"></noscript><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript><link rel="preload" href="lib/styles/snippets.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/snippets.css"></noscript></head><body class="publish css-settings-manager theme-dark show-inline-title highlightr-rounded"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles">mjx-mfrac { display: inline-block; text-align: left; }
mjx-frac { display: inline-block; vertical-align: 0.17em; padding: 0px 0.22em; }
mjx-frac[type="d"] { vertical-align: 0.04em; }
mjx-frac[delims] { padding: 0px 0.1em; }
mjx-frac[atop] { padding: 0px 0.12em; }
mjx-frac[atop][delims] { padding: 0px; }
mjx-dtable { display: inline-table; width: 100%; }
mjx-dtable > * { font-size: 2000%; }
mjx-dbox { display: block; font-size: 5%; }
mjx-num { display: block; text-align: center; }
mjx-den { display: block; text-align: center; }
mjx-mfrac[bevelled] > mjx-num { display: inline-block; }
mjx-mfrac[bevelled] > mjx-den { display: inline-block; }
mjx-den[align="right"], mjx-num[align="right"] { text-align: right; }
mjx-den[align="left"], mjx-num[align="left"] { text-align: left; }
mjx-nstrut { display: inline-block; height: 0.054em; width: 0px; vertical-align: -0.054em; }
mjx-nstrut[type="d"] { height: 0.217em; vertical-align: -0.217em; }
mjx-dstrut { display: inline-block; height: 0.505em; width: 0px; }
mjx-dstrut[type="d"] { height: 0.726em; }
mjx-line { display: block; box-sizing: border-box; min-height: 1px; height: 0.06em; border-top: 0.06em solid; margin: 0.06em -0.1em; overflow: hidden; }
mjx-line[type="d"] { margin: 0.18em -0.1em; }
mjx-mrow { display: inline-block; text-align: left; }
mjx-mtext { display: inline-block; text-align: left; }
mjx-c.mjx-c1D43A.TEX-I::before { padding: 0.705em 0.786em 0.022em 0px; content: "G"; }
mjx-c.mjx-c1D43F.TEX-I::before { padding: 0.683em 0.681em 0px 0px; content: "L"; }
mjx-c.mjx-c1D438.TEX-I::before { padding: 0.68em 0.764em 0px 0px; content: "E"; }
mjx-c.mjx-c1D445.TEX-I::before { padding: 0.683em 0.759em 0.021em 0px; content: "R"; }
mjx-c.mjx-c67::before { padding: 0.453em 0.5em 0.206em 0px; content: "g"; }
mjx-c.mjx-c72::before { padding: 0.442em 0.392em 0px 0px; content: "r"; }
mjx-c.mjx-c6F::before { padding: 0.448em 0.5em 0.01em 0px; content: "o"; }
mjx-c.mjx-c75::before { padding: 0.442em 0.556em 0.011em 0px; content: "u"; }
mjx-c.mjx-c6E::before { padding: 0.442em 0.556em 0px 0px; content: "n"; }
mjx-c.mjx-c64::before { padding: 0.694em 0.556em 0.011em 0px; content: "d"; }
mjx-c.mjx-c20::before { padding: 0px 0.25em 0px 0px; content: " "; }
mjx-c.mjx-c74::before { padding: 0.615em 0.389em 0.01em 0px; content: "t"; }
mjx-c.mjx-c68::before { padding: 0.694em 0.556em 0px 0px; content: "h"; }
mjx-c.mjx-c70::before { padding: 0.442em 0.556em 0.194em 0px; content: "p"; }
mjx-c.mjx-c65::before { padding: 0.448em 0.444em 0.011em 0px; content: "e"; }
mjx-c.mjx-c66::before { padding: 0.705em 0.372em 0px 0px; content: "f"; }
mjx-c.mjx-c6D::before { padding: 0.442em 0.833em 0px 0px; content: "m"; }
mjx-c.mjx-c61::before { padding: 0.448em 0.5em 0.011em 0px; content: "a"; }
mjx-c.mjx-c63::before { padding: 0.448em 0.444em 0.011em 0px; content: "c"; }
mjx-c.mjx-c2212::before { padding: 0.583em 0.778em 0.082em 0px; content: "âˆ’"; }
mjx-c.mjx-c6C::before { padding: 0.694em 0.278em 0px 0px; content: "l"; }
mjx-c.mjx-c62::before { padding: 0.694em 0.556em 0.011em 0px; content: "b"; }
mjx-c.mjx-c2D::before { padding: 0.252em 0.333em 0px 0px; content: "-"; }
mjx-mn { display: inline-block; text-align: left; }
mjx-c.mjx-c1D458.TEX-I::before { padding: 0.694em 0.521em 0.011em 0px; content: "k"; }
mjx-c.mjx-c3D::before { padding: 0.583em 0.778em 0.082em 0px; content: "="; }
mjx-c.mjx-c31::before { padding: 0.666em 0.5em 0px 0px; content: "1"; }
mjx-c.mjx-c36::before { padding: 0.666em 0.5em 0.022em 0px; content: "6"; }
mjx-container[jax="CHTML"] { line-height: 0; }
mjx-container [space="1"] { margin-left: 0.111em; }
mjx-container [space="2"] { margin-left: 0.167em; }
mjx-container [space="3"] { margin-left: 0.222em; }
mjx-container [space="4"] { margin-left: 0.278em; }
mjx-container [space="5"] { margin-left: 0.333em; }
mjx-container [rspace="1"] { margin-right: 0.111em; }
mjx-container [rspace="2"] { margin-right: 0.167em; }
mjx-container [rspace="3"] { margin-right: 0.222em; }
mjx-container [rspace="4"] { margin-right: 0.278em; }
mjx-container [rspace="5"] { margin-right: 0.333em; }
mjx-container [size="s"] { font-size: 70.7%; }
mjx-container [size="ss"] { font-size: 50%; }
mjx-container [size="Tn"] { font-size: 60%; }
mjx-container [size="sm"] { font-size: 85%; }
mjx-container [size="lg"] { font-size: 120%; }
mjx-container [size="Lg"] { font-size: 144%; }
mjx-container [size="LG"] { font-size: 173%; }
mjx-container [size="hg"] { font-size: 207%; }
mjx-container [size="HG"] { font-size: 249%; }
mjx-container [width="full"] { width: 100%; }
mjx-box { display: inline-block; }
mjx-block { display: block; }
mjx-itable { display: inline-table; }
mjx-row { display: table-row; }
mjx-row > * { display: table-cell; }
mjx-mtext { display: inline-block; }
mjx-mstyle { display: inline-block; }
mjx-merror { display: inline-block; color: red; background-color: yellow; }
mjx-mphantom { visibility: hidden; }
mjx-assistive-mml { top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); user-select: none; position: absolute !important; padding: 1px 0px 0px !important; border: 0px !important; display: block !important; width: auto !important; overflow: hidden !important; }
mjx-assistive-mml[display="block"] { width: 100% !important; }
mjx-math { display: inline-block; text-align: left; line-height: 0; text-indent: 0px; font-style: normal; font-weight: normal; font-size: 100%; letter-spacing: normal; border-collapse: collapse; overflow-wrap: normal; word-spacing: normal; white-space: nowrap; direction: ltr; padding: 1px 0px; }
mjx-container[jax="CHTML"][display="true"] { display: block; text-align: center; margin: 1em 0px; }
mjx-container[jax="CHTML"][display="true"][width="full"] { display: flex; }
mjx-container[jax="CHTML"][display="true"] mjx-math { padding: 0px; }
mjx-container[jax="CHTML"][justify="left"] { text-align: left; }
mjx-container[jax="CHTML"][justify="right"] { text-align: right; }
mjx-mi { display: inline-block; text-align: left; }
mjx-c { display: inline-block; }
mjx-utext { display: inline-block; padding: 0.75em 0px 0.2em; }
mjx-mo { display: inline-block; text-align: left; }
mjx-stretchy-h { display: inline-table; width: 100%; }
mjx-stretchy-h > * { display: table-cell; width: 0px; }
mjx-stretchy-h > * > mjx-c { display: inline-block; transform: scaleX(1); }
mjx-stretchy-h > * > mjx-c::before { display: inline-block; width: initial; }
mjx-stretchy-h > mjx-ext { overflow: clip visible; width: 100%; }
mjx-stretchy-h > mjx-ext > mjx-c::before { transform: scaleX(500); }
mjx-stretchy-h > mjx-ext > mjx-c { width: 0px; }
mjx-stretchy-h > mjx-beg > mjx-c { margin-right: -0.1em; }
mjx-stretchy-h > mjx-end > mjx-c { margin-left: -0.1em; }
mjx-stretchy-v { display: inline-block; }
mjx-stretchy-v > * { display: block; }
mjx-stretchy-v > mjx-beg { height: 0px; }
mjx-stretchy-v > mjx-end > mjx-c { display: block; }
mjx-stretchy-v > * > mjx-c { transform: scaleY(1); transform-origin: left center; overflow: hidden; }
mjx-stretchy-v > mjx-ext { display: block; height: 100%; box-sizing: border-box; border: 0px solid transparent; overflow: visible clip; }
mjx-stretchy-v > mjx-ext > mjx-c::before { width: initial; box-sizing: border-box; }
mjx-stretchy-v > mjx-ext > mjx-c { transform: scaleY(500) translateY(0.075em); overflow: visible; }
mjx-mark { display: inline-block; height: 0px; }
mjx-c::before { display: block; width: 0px; }
.MJX-TEX { font-family: MJXZERO, MJXTEX; }
.TEX-B { font-family: MJXZERO, MJXTEX-B; }
.TEX-I { font-family: MJXZERO, MJXTEX-I; }
.TEX-MI { font-family: MJXZERO, MJXTEX-MI; }
.TEX-BI { font-family: MJXZERO, MJXTEX-BI; }
.TEX-S1 { font-family: MJXZERO, MJXTEX-S1; }
.TEX-S2 { font-family: MJXZERO, MJXTEX-S2; }
.TEX-S3 { font-family: MJXZERO, MJXTEX-S3; }
.TEX-S4 { font-family: MJXZERO, MJXTEX-S4; }
.TEX-A { font-family: MJXZERO, MJXTEX-A; }
.TEX-C { font-family: MJXZERO, MJXTEX-C; }
.TEX-CB { font-family: MJXZERO, MJXTEX-CB; }
.TEX-FR { font-family: MJXZERO, MJXTEX-FR; }
.TEX-FRB { font-family: MJXZERO, MJXTEX-FRB; }
.TEX-SS { font-family: MJXZERO, MJXTEX-SS; }
.TEX-SSB { font-family: MJXZERO, MJXTEX-SSB; }
.TEX-SSI { font-family: MJXZERO, MJXTEX-SSI; }
.TEX-SC { font-family: MJXZERO, MJXTEX-SC; }
.TEX-T { font-family: MJXZERO, MJXTEX-T; }
.TEX-V { font-family: MJXZERO, MJXTEX-V; }
.TEX-VB { font-family: MJXZERO, MJXTEX-VB; }
mjx-stretchy-v mjx-c, mjx-stretchy-h mjx-c { font-family: MJXZERO, MJXTEX-S1, MJXTEX-S4, MJXTEX, MJXTEX-A !important; }
@font-face { font-family: MJXZERO; src: url("lib/fonts/mathjax_zero.woff") format("woff"); }
@font-face { font-family: MJXTEX; src: url("lib/fonts/mathjax_main-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-B; src: url("lib/fonts/mathjax_main-bold.woff") format("woff"); }
@font-face { font-family: MJXTEX-I; src: url("lib/fonts/mathjax_math-italic.woff") format("woff"); }
@font-face { font-family: MJXTEX-MI; src: url("lib/fonts/mathjax_main-italic.woff") format("woff"); }
@font-face { font-family: MJXTEX-BI; src: url("lib/fonts/mathjax_math-bolditalic.woff") format("woff"); }
@font-face { font-family: MJXTEX-S1; src: url("lib/fonts/mathjax_size1-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-S2; src: url("lib/fonts/mathjax_size2-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-S3; src: url("lib/fonts/mathjax_size3-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-S4; src: url("lib/fonts/mathjax_size4-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-A; src: url("lib/fonts/mathjax_ams-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-C; src: url("lib/fonts/mathjax_calligraphic-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-CB; src: url("lib/fonts/mathjax_calligraphic-bold.woff") format("woff"); }
@font-face { font-family: MJXTEX-FR; src: url("lib/fonts/mathjax_fraktur-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-FRB; src: url("lib/fonts/mathjax_fraktur-bold.woff") format("woff"); }
@font-face { font-family: MJXTEX-SS; src: url("lib/fonts/mathjax_sansserif-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-SSB; src: url("lib/fonts/mathjax_sansserif-bold.woff") format("woff"); }
@font-face { font-family: MJXTEX-SSI; src: url("lib/fonts/mathjax_sansserif-italic.woff") format("woff"); }
@font-face { font-family: MJXTEX-SC; src: url("lib/fonts/mathjax_script-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-T; src: url("lib/fonts/mathjax_typewriter-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-V; src: url("lib/fonts/mathjax_vector-regular.woff") format("woff"); }
@font-face { font-family: MJXTEX-VB; src: url("lib/fonts/mathjax_vector-bold.woff") format("woff"); }
mjx-c.mjx-c1D443.TEX-I::before { padding: 0.683em 0.751em 0px 0px; content: "P"; }
mjx-c.mjx-c28::before { padding: 0.75em 0.389em 0.25em 0px; content: "("; }
mjx-c.mjx-c1D45C.TEX-I::before { padding: 0.441em 0.485em 0.011em 0px; content: "o"; }
mjx-c.mjx-c1D462.TEX-I::before { padding: 0.442em 0.572em 0.011em 0px; content: "u"; }
mjx-c.mjx-c1D461.TEX-I::before { padding: 0.626em 0.361em 0.011em 0px; content: "t"; }
mjx-c.mjx-c1D45D.TEX-I::before { padding: 0.442em 0.503em 0.194em 0px; content: "p"; }
mjx-c.mjx-c7C::before { padding: 0.75em 0.278em 0.249em 0px; content: "|"; }
mjx-c.mjx-c1D456.TEX-I::before { padding: 0.661em 0.345em 0.011em 0px; content: "i"; }
mjx-c.mjx-c1D45B.TEX-I::before { padding: 0.442em 0.6em 0.011em 0px; content: "n"; }
mjx-c.mjx-c29::before { padding: 0.75em 0.389em 0.25em 0px; content: ")"; }
</style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="Ground Truth <em>Kinda</em> Matters - About the In's and Out's of In-Context Learning">Ground Truth <em>Kinda</em> Matters - About the In's and Out's of In-Context Learning</h1><div class="heading-wrapper"><div class="heading-children"><div class="heading-wrapper"><h2 data-heading="Introduction: In-context learning" class="heading" id="Introduction:_In-context_learning"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Introduction: In-context learning</h2><div class="heading-children"><div><p>With LLMs being all the rage currently, one big question is: how do we use them? Instead of small models trained to do a specific task, we now also have language models with billions of parameters that can be used for many different tasks. </p></div><div><p>One way to get a language model to do a certain task is...</p></div><div><div data-callout-metadata="" data-callout-fold="" data-callout="basic" class="callout"><div class="callout-title"><div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-star"><polygon points="12 2 15.09 8.26 22 9.27 17 14.14 18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26 12 2"></polygon></svg></div><div class="callout-title-inner"> In-context learning (ICL)</div></div><div class="callout-content">
<p>The basic idea behind in-context learning is to give a language model a few examples of inputs and corresponding outputs before letting it predict the outputs for new inputs.<br>
Intuitively, the examples demonstrate the task in hopes of the model generalizing from them to do the task (better).</p>
</div></div></div><div><p>Now that you know what in-context learning is, we can dive into the main parts of this post. There are two parts, each of them breaking down one paper. Both try to answer the question of <strong>how and why in-context learning works</strong>. By the end, you hopefully have gained a better understanding of what goes into in-context learning and how the authors of the papers studied this.</p></div><div><hr></div></div></div><div class="heading-wrapper"><h2 data-heading="Part 1: &quot;Ground Truth Matters Little&quot;" class="heading" id="Part_1:_&quot;Ground_Truth_Matters_Little&quot;"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Part 1: "Ground Truth Matters Little"</h2><div class="heading-children"><div><p>The main paper this post focuses on is called "Rethinking the role of demonstrations: What makes in-context learning work?"<sup data-footnote-id="fnref-1-4f555327d975d61d" class="footnote-ref" id="fnref-1-4f555327d975d61d"><a href="#fn-1-4f555327d975d61d" class="footnote-link" target="_self" rel="noopener">[1]</a></sup>. It came out in early 2022 and was one of the first to explore how and why in-context learning works.</p></div><div><p>Here's an overview showing you what to expect in this first part:</p></div><div><ol>
<li data-line="0"><a class="internal-link" data-href="#Details about the experiments" href="#Details_about_the_experiments" target="_self" rel="noopener">Details about the experiments</a></li>
<li data-line="1"><a class="internal-link" data-href="#Gold labels vs random labels" href="#Gold_labels_vs_random_labels" target="_self" rel="noopener">Gold labels vs random labels</a></li>
<li data-line="2"><a class="internal-link" data-href="#What does not matter for ICL?" href="#What_does_not_matter_for_ICL?" target="_self" rel="noopener">What does not matter for ICL?</a></li>
<li data-line="3"><a class="internal-link" data-href="#Ok, but ...what makes ICL work then?" href="#Ok,_but_...what_makes_ICL_work_then?" target="_self" rel="noopener">What makes ICL work then?</a></li>
<li data-line="4"><a class="internal-link" data-href="#Recap and Discussion" href="#Recap_and_Discussion" target="_self" rel="noopener">Recap and Discussion</a></li>
</ol></div><div class="heading-wrapper"><h3 data-heading="Details about the experiments" class="heading" id="Details_about_the_experiments"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Details about the experiments</h3><div class="heading-children"><div class="heading-wrapper"><h4 data-heading="Models" class="heading" id="Models"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Models</h4><div class="heading-children"><div><p>The authors used these 6 different LLMs in their experiments:</p></div><div style="overflow-x: auto;"><table>
<thead>
<tr>
<th>Name</th>
<th>Parameters</th>
<th>Good to know</th>
<th>Links</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-2 Large</td>
<td>774M</td>
<td></td>
<td><a data-tooltip-position="top" aria-label="https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf" rel="noopener" class="external-link" href="https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf" target="_blank">Paper</a>, <a data-tooltip-position="top" aria-label="https://paperswithcode.com/paper/language-models-are-unsupervised-multitask" rel="noopener" class="external-link" href="https://paperswithcode.com/paper/language-models-are-unsupervised-multitask" target="_blank">PapersWithCode</a>, <a data-tooltip-position="top" aria-label="https://huggingface.co/openai-community/gpt2-large" rel="noopener" class="external-link" href="https://huggingface.co/openai-community/gpt2-large" target="_blank">Huggingface</a></td>
</tr>
<tr>
<td>MetaICL</td>
<td>774M</td>
<td>fine-tuned on in-context learning, based on GPT-2 Large</td>
<td><a data-tooltip-position="top" aria-label="https://aclanthology.org/2022.naacl-main.201/" rel="noopener" class="external-link" href="https://aclanthology.org/2022.naacl-main.201/" target="_blank">Paper</a>, <a data-tooltip-position="top" aria-label="https://paperswithcode.com/paper/metaicl-learning-to-learn-in-context" rel="noopener" class="external-link" href="https://paperswithcode.com/paper/metaicl-learning-to-learn-in-context" target="_blank">PapersWithCode</a></td>
</tr>
<tr>
<td>GPT-J</td>
<td>6B</td>
<td>open-source replication of GPT-3</td>
<td><a data-tooltip-position="top" aria-label="https://github.com/kingoflolz/mesh-transformer-jax" rel="noopener" class="external-link" href="https://github.com/kingoflolz/mesh-transformer-jax" target="_blank">GitHub</a>, <a data-tooltip-position="top" aria-label="https://huggingface.co/EleutherAI/gpt-j-6b" rel="noopener" class="external-link" href="https://huggingface.co/EleutherAI/gpt-j-6b" target="_blank">Huggingface</a></td>
</tr>
<tr>
<td>fairseq</td>
<td>6.7B</td>
<td></td>
<td><a data-tooltip-position="top" aria-label="https://arxiv.org/pdf/2112.10684.pdf" rel="noopener" class="external-link" href="https://arxiv.org/pdf/2112.10684.pdf" target="_blank">Paper</a>, <a data-tooltip-position="top" aria-label="https://github.com/facebookresearch/fairseq/tree/main/examples/moe_lm" rel="noopener" class="external-link" href="https://github.com/facebookresearch/fairseq/tree/main/examples/moe_lm" target="_blank">GitHub</a>, <a data-tooltip-position="top" aria-label="https://huggingface.co/KoboldAI/fairseq-dense-6.7B" rel="noopener" class="external-link" href="https://huggingface.co/KoboldAI/fairseq-dense-6.7B" target="_blank">Huggingface</a></td>
</tr>
<tr>
<td>fairseq</td>
<td>13B</td>
<td>largest publicly released dense LM at the time; developed by Meta</td>
<td><a data-tooltip-position="top" aria-label="https://arxiv.org/pdf/2112.10684.pdf" rel="noopener" class="external-link" href="https://arxiv.org/pdf/2112.10684.pdf" target="_blank">Paper</a>, <a data-tooltip-position="top" aria-label="https://github.com/facebookresearch/fairseq/tree/main/examples/moe_lm" rel="noopener" class="external-link" href="https://github.com/facebookresearch/fairseq/tree/main/examples/moe_lm" target="_blank">GitHub</a>, <a data-tooltip-position="top" aria-label="https://huggingface.co/KoboldAI/fairseq-dense-13B" rel="noopener" class="external-link" href="https://huggingface.co/KoboldAI/fairseq-dense-13B" target="_blank">Huggingface</a></td>
</tr>
<tr>
<td>GPT-3, davinci-base</td>
<td>175B</td>
<td>largest dense LM at the time</td>
<td><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2005.14165" rel="noopener" class="external-link" href="https://arxiv.org/abs/2005.14165" target="_blank">Paper</a>, <a data-tooltip-position="top" aria-label="https://paperswithcode.com/paper/language-models-are-few-shot-learners" rel="noopener" class="external-link" href="https://paperswithcode.com/paper/language-models-are-few-shot-learners" target="_blank">PapersWithCode</a>, <a data-tooltip-position="top" aria-label="https://github.com/openai/gpt-3" rel="noopener" class="external-link" href="https://github.com/openai/gpt-3" target="_blank">GitHub</a></td>
</tr>
</tbody>
</table></div><div><p>Each of this models was used with with two different inference methods, <strong>direct</strong> inference and <strong>noisy channel</strong> inference.</p></div><div><div data-callout-metadata="" data-callout-fold="" data-callout="btw" class="callout"><div class="callout-title"><div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-info"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg></div><div class="callout-title-inner">Direct vs Noisy Channel <sup data-footnote-id="fnref-2-4f555327d975d61d" class="footnote-ref" id="fnref-2-4f555327d975d61d"><a href="#fn-2-4f555327d975d61d" class="footnote-link" target="_self" rel="noopener">[2]</a></sup></div></div><div class="callout-content">
<p>The difference between these two inference methods lies in the calculated probabilities.</p>
<p><strong>Direct</strong> models simply calculate <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math></mjx-container></span>, so we are trying to find the output with the largest probability given the input.</p>
<p><strong>Noisy channel</strong> models take a slightly different approach: they try to maximize <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math></mjx-container></span>. Intuitively, the noisy channel method assumes that the input contains some noise, and that the goal is to reconstruct the version without noise - the output. This is more often used in areas where this intuition comes more naturally, like transcriptions or machine translations.</p>
<p>You may be able to see how these probabilities easily relate to each other via Bayes' rule. A nice advantage of the noisy channel method is that it splits the probability into two parts, and the second part, <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45D TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D461 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math></mjx-container></span>, can often be modelled independently from the task at hand. </p>
</div></div></div></div></div><div class="heading-wrapper"><h4 data-heading="Datasets" class="heading" id="Datasets"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Datasets</h4><div class="heading-children"><div><p>The 26 datasets used in the experiments cover a wide variety of domains, with a focus on smaller datasets that pass the <a data-tooltip-position="top" aria-label="https://gluebenchmark.com/" rel="noopener" class="external-link" href="https://gluebenchmark.com/" target="_blank">GLUE</a> and <a data-tooltip-position="top" aria-label="https://super.gluebenchmark.com/" rel="noopener" class="external-link" href="https://super.gluebenchmark.com/" target="_blank">SuperGLUE</a> benchmarks. There are two types of tasks:</p></div><div><ol>
<li data-line="0">classification, e.g. sentiment analysis</li>
<li data-line="1">multi-choice, e.g. question answering</li>
</ol></div></div></div><div class="heading-wrapper"><h4 data-heading="Procedure" class="heading" id="Procedure"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Procedure</h4><div class="heading-children"><div><p>The researchers arrived at a single combined score per model and task type with the following procedure:</p></div><div class="code-block-wrap"><div class="mermaid"><svg aria-roledescription="flowchart-v2" role="graphics-document document" viewBox="-8 -8 547.0703125 522.375" height="522.375" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" width="547.0703125" id="m0c59c1e261152927"><style>#m0c59c1e261152927{font-family:var(--font-mermaid);font-size:16px;fill:var(--text-normal);}#m0c59c1e261152927 .error-icon{fill:var(--background-primary);}#m0c59c1e261152927 .error-text{fill:var(--text-error);stroke:var(--text-error);}#m0c59c1e261152927 .edge-thickness-normal{stroke-width:2px;}#m0c59c1e261152927 .edge-thickness-thick{stroke-width:3.5px;}#m0c59c1e261152927 .edge-pattern-solid{stroke-dasharray:0;}#m0c59c1e261152927 .edge-pattern-dashed{stroke-dasharray:3;}#m0c59c1e261152927 .edge-pattern-dotted{stroke-dasharray:2;}#m0c59c1e261152927 .marker{fill:var(--text-normal);stroke:var(--text-normal);}#m0c59c1e261152927 .marker.cross{stroke:var(--text-normal);}#m0c59c1e261152927 svg{font-family:var(--font-mermaid);font-size:16px;}#m0c59c1e261152927 .label{font-family:var(--font-mermaid);color:var(--text-normal);}#m0c59c1e261152927 .cluster-label text{fill:var(--text-normal);}#m0c59c1e261152927 .cluster-label span,#m0c59c1e261152927 p{color:var(--text-normal);}#m0c59c1e261152927 .label text,#m0c59c1e261152927 span,#m0c59c1e261152927 p{fill:var(--text-normal);color:var(--text-normal);}#m0c59c1e261152927 .node rect,#m0c59c1e261152927 .node circle,#m0c59c1e261152927 .node ellipse,#m0c59c1e261152927 .node polygon,#m0c59c1e261152927 .node path{fill:var(--background-primary);stroke:var(--text-muted);stroke-width:1px;}#m0c59c1e261152927 .flowchart-label text{text-anchor:middle;}#m0c59c1e261152927 .node .label{text-align:center;}#m0c59c1e261152927 .node.clickable{cursor:pointer;}#m0c59c1e261152927 .arrowheadPath{fill:#0b0b0b;}#m0c59c1e261152927 .edgePath .path{stroke:var(--text-normal);stroke-width:2.0px;}#m0c59c1e261152927 .flowchart-link{stroke:var(--text-normal);fill:none;}#m0c59c1e261152927 .edgeLabel{background-color:var(--background-secondary);text-align:center;}#m0c59c1e261152927 .edgeLabel rect{opacity:0.5;background-color:var(--background-secondary);fill:var(--background-secondary);}#m0c59c1e261152927 .labelBkg{background-color:var(--background-secondary);}#m0c59c1e261152927 .cluster rect{fill:hsl(220.5882352941, 100%, 98.3333333333%);stroke:hsl(220.5882352941, 60%, 88.3333333333%);stroke-width:1px;}#m0c59c1e261152927 .cluster text{fill:var(--text-normal);}#m0c59c1e261152927 .cluster span,#m0c59c1e261152927 p{color:var(--text-normal);}#m0c59c1e261152927 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:var(--font-mermaid);font-size:12px;background:var(--background-secondary-alt);border:1px solid hsl(220.5882352941, 60%, 88.3333333333%);border-radius:2px;pointer-events:none;z-index:100;}#m0c59c1e261152927 .flowchartTitleText{text-anchor:middle;font-size:18px;fill:var(--text-normal);}#m0c59c1e261152927 foreignObject{overflow:visible;}#m0c59c1e261152927 #arrowhead,#m0c59c1e261152927 #sequencenumber,#m0c59c1e261152927 .cluster text,#m0c59c1e261152927 .label text,#m0c59c1e261152927 text,#m0c59c1e261152927 text.actor{fill:var(--text-normal);}#m0c59c1e261152927 line{stroke:var(--text-normal);}#m0c59c1e261152927 g&gt;g&gt;circle,#m0c59c1e261152927 g&gt;g&gt;path{stroke:var(--background-accent);color:var(--text-normal);}#m0c59c1e261152927 .label rect{display:none;}#m0c59c1e261152927 .cluster rect{stroke-width:1px;}#m0c59c1e261152927 .node circle,#m0c59c1e261152927 .node ellipse,#m0c59c1e261152927 .node path,#m0c59c1e261152927 .node polygon,#m0c59c1e261152927 .node rect{fill:var(--background-secondary-alt);stroke:var(--background-modifier-border);stroke-width:1px;}#m0c59c1e261152927 .node .label{text-align:center;}#m0c59c1e261152927 .node.clickable{cursor:pointer;}#m0c59c1e261152927 .arrowheadPath{fill:var(--text-muted);}#m0c59c1e261152927 .edgePath .path{stroke:var(--text-muted);stroke-width:1.5px;}#m0c59c1e261152927 .edgeLabel{background-color:var(--background-primary);text-align:center;}#m0c59c1e261152927 .cluster rect{fill:var(--background-primary-alt);stroke:var(--background-modifier-border);}#m0c59c1e261152927 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-size:12px;background:var(--background-secondary);border:1px solid var(--interactive-accent);border-radius:2px;pointer-events:none;z-index:100;}#m0c59c1e261152927 .actor{stroke:var(--background-modifier-border);fill:var(--background-secondary-alt);font-family:inherit!important;}#m0c59c1e261152927 text.actor{stroke:none;}#m0c59c1e261152927 .actor-line{stroke:var(--text-muted);}#m0c59c1e261152927 .messageLine0,#m0c59c1e261152927 .messageLine1{stroke-width:1.5;stroke-dasharray:'2 2';stroke:var(--text-normal);}#m0c59c1e261152927 #crosshead path{fill:var(--text-normal)!important;stroke:var(--text-normal)!important;}#m0c59c1e261152927 .messageText{fill:var(--text-normal);stroke:none;font-family:inherit!important;}#m0c59c1e261152927 .labelBox{stroke:var(--background-modifier-border);fill:var(--background-secondary-alt);}#m0c59c1e261152927 .labelText,#m0c59c1e261152927 .loopText{fill:var(--text-normal);stroke:none;}#m0c59c1e261152927 .loopLine{stroke-width:2;stroke-dasharray:'2 2';stroke:var(--background-modifier-border);}#m0c59c1e261152927 .activation0,#m0c59c1e261152927 .activation1,#m0c59c1e261152927 .activation2{fill:var(--background-secondary) stroke:var(--text-muted);}#m0c59c1e261152927 .section{stroke:none;opacity:.2;}#m0c59c1e261152927 .section0,#m0c59c1e261152927 .section2{fill:var(--text-accent);}#m0c59c1e261152927 .section1,#m0c59c1e261152927 .section3{fill:#fff;opacity:.2;}#m0c59c1e261152927 .sectionTitle0,#m0c59c1e261152927 .sectionTitle1,#m0c59c1e261152927 .sectionTitle2,#m0c59c1e261152927 .sectionTitle3{fill:var(--text-normal);}#m0c59c1e261152927 .sectionTitle{text-anchor:start;font-size:11px;text-height:14px;}#m0c59c1e261152927 .grid .tick{stroke:var(--background-primary-alt);opacity:.8;shape-rendering:crispEdges;}#m0c59c1e261152927 .grid path{stroke-width:0;}#m0c59c1e261152927 .today{fill:none;stroke:#d42;stroke-width:2px;}#m0c59c1e261152927 .task{stroke-width:2;}#m0c59c1e261152927 .taskText{text-anchor:middle;}#m0c59c1e261152927 .taskText:not([font-size]){font-size:11px;}#m0c59c1e261152927 .taskTextOutsideRight{fill:var(--text-normal);text-anchor:start;font-size:11px;}#m0c59c1e261152927 .taskTextOutsideLeft{fill:var(--text-normal);text-anchor:end;font-size:11px;}#m0c59c1e261152927 .task.clickable,#m0c59c1e261152927 g.clickable{cursor:pointer;}#m0c59c1e261152927 .taskText.clickable,#m0c59c1e261152927 .taskTextOutsideLeft.clickable,#m0c59c1e261152927 .taskTextOutsideRight.clickable{cursor:pointer;fill:#003163!important;font-weight:700;}#m0c59c1e261152927 .taskText0,#m0c59c1e261152927 .taskText1,#m0c59c1e261152927 .taskText2,#m0c59c1e261152927 .taskText3{fill:#fff;}#m0c59c1e261152927 .task0,#m0c59c1e261152927 .task1,#m0c59c1e261152927 .task2,#m0c59c1e261152927 .task3{fill:var(--interactive-accent);stroke:var(--interactive-accent);}#m0c59c1e261152927 .taskTextOutside0,#m0c59c1e261152927 .taskTextOutside1,#m0c59c1e261152927 .taskTextOutside2,#m0c59c1e261152927 .taskTextOutside3{fill:var(--text-normal);}#m0c59c1e261152927 .active0,#m0c59c1e261152927 .active1,#m0c59c1e261152927 .active2,#m0c59c1e261152927 .active3,#m0c59c1e261152927 g.classGroup rect,#m0c59c1e261152927 g.stateGroup rect{fill:var(--background-primary-alt);stroke:var(--background-modifier-border);}#m0c59c1e261152927 g.classGroup rect,#m0c59c1e261152927 g.stateGroup rect{stroke:var(--background-modifier-border);}#m0c59c1e261152927 .activeText0,#m0c59c1e261152927 .activeText1,#m0c59c1e261152927 .activeText2,#m0c59c1e261152927 .activeText3{fill:var(--text-normal)!important;}#m0c59c1e261152927 .done0,#m0c59c1e261152927 .done1,#m0c59c1e261152927 .done2,#m0c59c1e261152927 .done3{stroke:var(--text-muted);fill:#bbb;stroke-width:2;}#m0c59c1e261152927 .doneText0,#m0c59c1e261152927 .doneText1,#m0c59c1e261152927 .doneText2,#m0c59c1e261152927 .doneText3{fill:var(--text-normal)!important;}#m0c59c1e261152927 .crit0,#m0c59c1e261152927 .crit1,#m0c59c1e261152927 .crit2,#m0c59c1e261152927 .crit3{stroke:#b1361b;fill:#d42;stroke-width:2;}#m0c59c1e261152927 .activeCrit0,#m0c59c1e261152927 .activeCrit1,#m0c59c1e261152927 .activeCrit2,#m0c59c1e261152927 .activeCrit3,#m0c59c1e261152927 .classLabel .box{stroke:#b1361b;fill:var(--background-secondary-alt);stroke-width:2;}#m0c59c1e261152927 .classLabel .box{stroke:none;stroke-width:0;opacity:.5;}#m0c59c1e261152927 .doneCrit0,#m0c59c1e261152927 .doneCrit1,#m0c59c1e261152927 .doneCrit2,#m0c59c1e261152927 .doneCrit3{stroke:#b1361b;fill:#bbb;stroke-width:2;cursor:pointer;shape-rendering:crispEdges;}#m0c59c1e261152927 .milestone{transform:rotate(45deg) scale(.8,.8);}#m0c59c1e261152927 .milestoneText{font-style:italic;}#m0c59c1e261152927 .activeCritText0,#m0c59c1e261152927 .activeCritText1,#m0c59c1e261152927 .activeCritText2,#m0c59c1e261152927 .activeCritText3,#m0c59c1e261152927 .doneCritText0,#m0c59c1e261152927 .doneCritText1,#m0c59c1e261152927 .doneCritText2,#m0c59c1e261152927 .doneCritText3{fill:var(--text-normal)!important;}#m0c59c1e261152927 .titleText{text-anchor:middle;font-size:18px;fill:var(--text-normal);}#m0c59c1e261152927 g.classGroup text{fill:var(--text-normal);stroke:none;font-size:11px;}#m0c59c1e261152927 g.classGroup text .title{font-weight:bolder;}#m0c59c1e261152927 #aggregationEnd,#m0c59c1e261152927 #aggregationStart,#m0c59c1e261152927 #compositionEnd,#m0c59c1e261152927 #compositionStart,#m0c59c1e261152927 g.classGroup line,#m0c59c1e261152927 g.stateGroup line{stroke:var(--background-modifier-border);stroke-width:1;}#m0c59c1e261152927 .classLabel .label{font-size:11px;}#m0c59c1e261152927 .relation{fill:none;}#m0c59c1e261152927 .dashed-line{stroke-dasharray:3;}#m0c59c1e261152927 #compositionEnd,#m0c59c1e261152927 #compositionStart{fill:var(--background-modifier-border);}#m0c59c1e261152927 #aggregationEnd,#m0c59c1e261152927 #aggregationStart{fill:var(--background-secondary-alt);}#m0c59c1e261152927 #dependencyEnd,#m0c59c1e261152927 #dependencyStart,#m0c59c1e261152927 #extensionEnd,#m0c59c1e261152927 #extensionStart{fill:var(--background-modifier-border);stroke:var(--background-modifier-border);stroke-width:1;}#m0c59c1e261152927 .branch-label,#m0c59c1e261152927 .commit-id,#m0c59c1e261152927 .commit-msg{fill:#d3d3d3;color:#d3d3d3;}#m0c59c1e261152927 .pieTitleText{text-anchor:middle;font-size:25px;fill:var(--text-normal);}#m0c59c1e261152927 .state-note text,#m0c59c1e261152927 g.stateGroup text{stroke:none;font-size:10px;}#m0c59c1e261152927 g.stateGroup .state-title{font-weight:bolder;fill:var(--text-normal);}#m0c59c1e261152927 .stateGroup .composit{fill:#fff;border-bottom:1px;}#m0c59c1e261152927 .stateGroup .alt-composit{fill:#e0e0e0;border-bottom:1px;}#m0c59c1e261152927 .state-note{stroke:#645c10;fill:#f3edb3;}#m0c59c1e261152927 .state-note text{fill:#000;}#m0c59c1e261152927 .stateLabel .box{stroke:none;stroke-width:0;fill:var(--background-secondary-alt);opacity:.5;}#m0c59c1e261152927 .stateLabel text{fill:var(--text-normal);font-size:10px;font-weight:700;}#m0c59c1e261152927 .node circle.state-start{fill:var(--text-normal);stroke:var(--text-normal);}#m0c59c1e261152927 .node circle.state-end{stroke:var(--background-primary);stroke-width:2;}#m0c59c1e261152927 #statediagram-barbEnd,#m0c59c1e261152927 g.stateGroup text{fill:var(--background-modifier-border);}#m0c59c1e261152927 .statediagram-cluster rect{stroke-width:1px;}#m0c59c1e261152927 .statediagram-cluster rect,#m0c59c1e261152927 .statediagram-state .divider{stroke:var(--background-modifier-border);}#m0c59c1e261152927 .statediagram-cluster rect .inner{fill:var(--background-secondary-alt);}#m0c59c1e261152927 .statediagram-cluster.statediagram-cluster-alt .inner{fill:var(--background-secondary);}#m0c59c1e261152927 .cluster-label text,#m0c59c1e261152927 .node circle.state-end{fill:var(--text-normal);}#m0c59c1e261152927 .statediagram-state rect.divider{stroke-dasharray:10,10;fill:var(--background-secondary);}#m0c59c1e261152927 .note-edge{stroke-dasharray:5;}#m0c59c1e261152927 .statediagram-note rect{fill:#f3edb3;stroke:#645c10;stroke-width:1px;}#m0c59c1e261152927 .error-icon{fill:var(--background-modifier-error);}#m0c59c1e261152927 .error-text{fill:var(--text-error);stroke:var(--text-error);}#m0c59c1e261152927 :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}</style><g><marker orient="auto" markerHeight="12" markerWidth="12" markerUnits="userSpaceOnUse" refY="5" refX="6" viewBox="0 0 10 10" class="marker flowchart" id="m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 0 L 10 5 L 0 10 z"></path></marker><marker orient="auto" markerHeight="12" markerWidth="12" markerUnits="userSpaceOnUse" refY="5" refX="4.5" viewBox="0 0 10 10" class="marker flowchart" id="m0c59c1e261152927-m0c59c1e261152927_flowchart-pointStart"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 5 L 10 10 L 10 0 z"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="11" viewBox="0 0 10 10" class="marker flowchart" id="m0c59c1e261152927-m0c59c1e261152927_flowchart-circleEnd"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="-1" viewBox="0 0 10 10" class="marker flowchart" id="m0c59c1e261152927-m0c59c1e261152927_flowchart-circleStart"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="12" viewBox="0 0 11 11" class="marker cross flowchart" id="m0c59c1e261152927-m0c59c1e261152927_flowchart-crossEnd"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="-1" viewBox="0 0 11 11" class="marker cross flowchart" id="m0c59c1e261152927-m0c59c1e261152927_flowchart-crossStart"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><g class="root"><g class="clusters"></g><g class="edgePaths"><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-S LE-E" id="L-S-E-0" d="M315.211,35.797L315.211,39.964C315.211,44.13,315.211,52.464,320.854,60.314C326.498,68.165,337.785,75.532,343.428,79.216L349.072,82.9"></path><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-A LE-E" id="L-A-E-0" d="M446.648,35.797L446.648,39.964C446.648,44.13,446.648,52.464,441.005,60.314C435.361,68.165,424.075,75.532,418.431,79.216L412.788,82.9"></path><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-M LE-R" id="L-M-R-0" d="M140.977,121.594L140.977,127.493C140.977,133.393,140.977,145.193,153.45,156.634C165.924,168.074,190.871,179.157,203.345,184.698L215.818,190.239"></path><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-E LE-R" id="L-E-R-0" d="M380.93,121.594L380.93,127.493C380.93,133.393,380.93,145.193,368.456,156.634C355.982,168.074,331.035,179.157,318.562,184.698L306.088,190.239"></path><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-R LE-C" id="L-R-C-0" d="M212.938,228.188L197.111,234.087C181.284,239.987,149.63,251.786,133.803,262.703C117.977,273.619,117.977,283.652,117.977,288.668L117.977,293.684"></path><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-R LE-D" id="L-R-D-0" d="M308.968,228.188L324.795,234.087C340.622,239.987,372.276,251.786,388.103,262.703C403.93,273.619,403.93,283.652,403.93,288.668L403.93,293.684"></path><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-C LE-F" id="L-C-F-0" d="M117.977,334.781L117.977,338.948C117.977,343.115,117.977,351.448,117.977,358.898C117.977,366.348,117.977,372.915,117.977,376.198L117.977,379.481"></path><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-F LE-G" id="L-F-G-0" d="M117.977,420.578L117.977,424.745C117.977,428.911,117.977,437.245,117.977,444.695C117.977,452.145,117.977,458.711,117.977,461.995L117.977,465.278"></path><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-D LE-H" id="L-D-H-0" d="M403.93,334.781L403.93,338.948C403.93,343.115,403.93,351.448,403.93,358.898C403.93,366.348,403.93,372.915,403.93,376.198L403.93,379.481"></path><path marker-end="url(#m0c59c1e261152927-m0c59c1e261152927_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-H LE-I" id="L-H-I-0" d="M403.93,420.578L403.93,424.745C403.93,428.911,403.93,437.245,403.93,444.695C403.93,452.145,403.93,458.711,403.93,461.995L403.93,465.278"></path></g><g class="edgeLabels"><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g transform="translate(140.9765625, 156.9921875)" class="edgeLabel"><g transform="translate(-90.9921875, -10.3984375)" class="label"><foreignObject height="20.796875" width="181.984375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel">2 inference methods each</span></div></foreignObject></g></g><g transform="translate(380.9296875, 156.9921875)" class="edgeLabel"><g transform="translate(-43.0625, -10.3984375)" class="label"><foreignObject height="20.796875" width="86.125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel">concatenate</span></div></foreignObject></g></g><g transform="translate(117.9765625, 263.5859375)" class="edgeLabel"><g transform="translate(-64.2421875, -10.3984375)" class="label"><foreignObject height="20.796875" width="128.484375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel">classification tasks</span></div></foreignObject></g></g><g transform="translate(403.9296875, 263.5859375)" class="edgeLabel"><g transform="translate(-63.671875, -10.3984375)" class="label"><foreignObject height="20.796875" width="127.34375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel">multi-choice tasks</span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g></g><g class="nodes"><g transform="translate(221.640625, 17.8984375)" id="flowchart-&amp;nbsp-140" class="node default default flowchart-label"><rect height="35.796875" width="19.390625" y="-17.8984375" x="-9.6953125" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-2.1953125, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="4.390625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">&nbsp;</span></div></foreignObject></g></g><g transform="translate(315.2109375, 17.8984375)" id="flowchart-S-142" class="node default default flowchart-label"><rect height="35.796875" width="67.75" y="-17.8984375" x="-33.875" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-26.375, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="52.75"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">5 seeds</span></div></foreignObject></g></g><g transform="translate(380.9296875, 103.6953125)" id="flowchart-E-143" class="node default default flowchart-label"><rect height="35.796875" width="300.28125" y="-17.8984375" x="-150.140625" ry="5" rx="5" style="" class="basic label-container"></rect><g transform="translate(-142.640625, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="285.28125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">sample k examples per seed and dataset</span></div></foreignObject></g></g><g transform="translate(446.6484375, 17.8984375)" id="flowchart-A-146" class="node default default flowchart-label"><rect height="35.796875" width="95.125" y="-17.8984375" x="-47.5625" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-40.0625, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="80.125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">26 datasets</span></div></foreignObject></g></g><g transform="translate(140.9765625, 103.6953125)" id="flowchart-M-150" class="node default default flowchart-label"><rect height="35.796875" width="79.625" y="-17.8984375" x="-39.8125" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-32.3125, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="64.625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">6 models</span></div></foreignObject></g></g><g transform="translate(260.953125, 210.2890625)" id="flowchart-R-151" class="node default default flowchart-label"><rect height="35.796875" width="129.390625" y="-17.8984375" x="-64.6953125" ry="5" rx="5" style="" class="basic label-container"></rect><g transform="translate(-57.1953125, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="114.390625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">run experiments</span></div></foreignObject></g></g><g transform="translate(117.9765625, 316.8828125)" id="flowchart-C-159" class="node default default flowchart-label"><rect height="35.796875" width="82.671875" y="-17.8984375" x="-41.3359375" ry="5" rx="5" style="" class="basic label-container"></rect><g transform="translate(-33.8359375, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="67.671875"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Macro-F1</span></div></foreignObject></g></g><g transform="translate(403.9296875, 316.8828125)" id="flowchart-D-163" class="node default default flowchart-label"><rect height="35.796875" width="78" y="-17.8984375" x="-39" ry="5" rx="5" style="" class="basic label-container"></rect><g transform="translate(-31.5, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="63"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Accuracy</span></div></foreignObject></g></g><g transform="translate(117.9765625, 402.6796875)" id="flowchart-F-167" class="node default default flowchart-label"><rect height="35.796875" width="235.953125" y="-17.8984375" x="-117.9765625" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-110.4765625, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="220.953125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">per-dataset average over seeds</span></div></foreignObject></g></g><g transform="translate(117.9765625, 488.4765625)" id="flowchart-G-171" class="node default default flowchart-label"><rect height="35.796875" width="219.546875" y="-17.8984375" x="-109.7734375" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-102.2734375, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="204.546875"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">macro-average over datasets</span></div></foreignObject></g></g><g transform="translate(403.9296875, 402.6796875)" id="flowchart-H-175" class="node default default flowchart-label"><rect height="35.796875" width="235.953125" y="-17.8984375" x="-117.9765625" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-110.4765625, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="220.953125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">per-dataset average over seeds</span></div></foreignObject></g></g><g transform="translate(403.9296875, 488.4765625)" id="flowchart-I-179" class="node default default flowchart-label"><rect height="35.796875" width="219.546875" y="-17.8984375" x="-109.7734375" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-102.2734375, -10.3984375)" style="" class="label"><rect></rect><foreignObject height="20.796875" width="204.546875"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">macro-average over datasets</span></div></foreignObject></g></g></g></g></g></svg></div></div><div><p>First, they used 5 seeds to sample <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math></mjx-container></span> examples from each dataset (default: <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math></mjx-container></span>), and each set of <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi></mjx-math></mjx-container></span> examples was concatenated. Then, each model was fed the example sets to make its predictions, one for each example set and inference method. The performance was then calculated as an average over the seeds and over the datasets.</p></div><div><p>If you're thinking: "That's a LOT of examples and runs", you'd be exactly right. That is why for the two largest models, they only used a subset of 6 datasets and 3 random seeds.</p></div><div><p>Now that we went over the setup, we are ready to dive into the different experiments and see what the results were!</p></div></div></div></div></div><div class="heading-wrapper"><h3 data-heading="Gold labels vs random labels" class="heading" id="Gold_labels_vs_random_labels"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Gold labels vs random labels</h3><div class="heading-children"><div><p>The main experiments in the paper focused on comparing the following three approaches:</p></div><div><ol>
<li data-line="0"><strong><span style="color:#80b1d3"><b>no demonstrations</b></span></strong>: a baseline without in-context learning, which means the model is not given any examples of input-output pairs</li>
<li data-line="1"><span style="color:#fdb462"><b>demonstrations with gold labels</b></span>: your usual in-context learning approach, in which the model is given <em>k</em> examples of inputs with their corresponding correct labels</li>
<li data-line="2"><span style="color:#fb8072"><b>demonstrations with random labels</b></span>: an approach where the model is given <em>k</em> examples just like in the previous approach, but the inputs are paired with randomly sampled labels</li>
</ol></div><div><p>This graph shows the performance of each model with each of the 3 approaches for each task category (classification and multi-choice):</p></div><div><p></p><div alt="Results of the main experiments, Figure 3 in the paper" src="pasted-image-20240306185652.png" class="internal-embed media-embed image-embed is-loaded"><figure class="image-captions-figure"><img alt="Results of the main experiments, Figure 3 in the paper" src="pasted-image-20240306185652.png"><figcaption class="image-captions-caption">Results of the main experiments, Figure 3 in the paper</figcaption></figure></div><p></p></div><div><p><strong>It seems that using random labels in the examples works pretty much almost as well as using random labels!</strong> This is already the main point of this paper. The authors admit that this is unexpected, because - well, shouldn't the information that certain inputs produce certain outputs matter? Why else should we even give examples in the first place?</p></div><div><p>To try and answer these questions, the paper presents a whole bunch of further experiments. First, we will look at some smaller ablations of the main experiment, and then explore what else might be hidden in the examples that helps models learn in-context.</p></div></div></div><div class="heading-wrapper"><h3 data-heading="What does not matter for ICL?" class="heading" id="What_does_not_matter_for_ICL?"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>What does not matter for ICL?</h3><div class="heading-children"><div><p>The following three experiments help investigate the main results. They were conducted on a smaller scale, using only the two best models (MetaICL and GPT-J) and 9 datasets (I'm sure the GPUs involved were grateful ðŸ™).</p></div><div class="heading-wrapper"><h5 data-heading="1. Does it matter *how many* correct labels are used?" class="heading" id="1._Does_it_matter_*how_many*_correct_labels_are_used?"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>1. Does it matter <em>how many</em> correct labels are used?</h5><div class="heading-children"><div><p>One thing about the <span style="color:#fb8072">random labels</span> method is that it is, well, random. In fact, the labels are sampled uniformly from <em>all</em> labels - which includes the correct ones. This means that there is a small chance that the some, or even most of the random labels are correct. Naturally, the comparison to the gold labels would not be as meaningful in that case.</p></div><div><p>The first ablation addresses this issue by using a range of fixed percentages of correct labels. </p></div><div><p></p><div alt="Results of experiments with varying percentages of correct labels, Figure 4 in the paper" src="pasted-image-20240306190239.png" class="internal-embed media-embed image-embed is-loaded"><figure class="image-captions-figure"><img alt="Results of experiments with varying percentages of correct labels, Figure 4 in the paper" src="pasted-image-20240306190239.png"><figcaption class="image-captions-caption">Results of experiments with varying percentages of correct labels, Figure 4 in the paper</figcaption></figure></div><p></p></div><div><p>The main takeaway here is: using examples with all wrong labels still seems to produce noticeably better results than the no-example baseline. Also, the MetaICL model seems to be especially robust in this aspect.</p></div></div></div><div class="heading-wrapper"><h5 data-heading="2. Does the number of examples matter?" class="heading" id="2._Does_the_number_of_examples_matter?"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>2. Does the number of examples matter?</h5><div class="heading-children"><div><p>As noted earlier, each experiment run used <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D458 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="4"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c36"></mjx-c></mjx-mn></mjx-math></mjx-container></span> examples. But especially with larger models, using long inputs can become vey costly . The second ablation therefore aims to see whether we really need that many examples to achieve the performance increases we've seen.<br>
</p></div><div><p></p><div alt="Results of experiments with varying numbers of demonstrations, Figure 5 in the paper" src="pasted-image-20240306190357.png" class="internal-embed media-embed image-embed is-loaded"><figure class="image-captions-figure"><img alt="Results of experiments with varying numbers of demonstrations, Figure 5 in the paper" src="pasted-image-20240306190357.png"><figcaption class="image-captions-caption">Results of experiments with varying numbers of demonstrations, Figure 5 in the paper</figcaption></figure></div><p></p></div><div><p>According to these results, increasing the number of examples beyond 8 does not really improve performance.</p></div></div></div><div class="heading-wrapper"><h5 data-heading="3. Does the way in which the examples are presented matter?" class="heading" id="3._Does_the_way_in_which_the_examples_are_presented_matter?"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>3. Does the way in which the examples are presented matter?</h5><div class="heading-children"><div><p>In the main experiments, the examples were simply concatenated without any additional context or structure. For the third ablation, the authors used what they describe as different templates for the examples.</p></div><div><p>Instead of just presenting the inputs and outputs, these templates are a way to add context and structure using short phrases or keywords that describe how inputs and outputs are related.</p></div><div><p>Here are some examples, taken from the paper's appendix, to show you the difference in how these templates present the <span style="color:#d3ff9e">inputs</span> and <span style="color:#fea9d2">outputs</span>:</p></div><div><blockquote>
<p><span style="color:#d3ff9e">What blocks sunshine?</span> \n {<span style="color:#fea9d2">summer|park|desktop|sea|moon</span>}<br>
The question is: <span style="color:#d3ff9e">What blocks sunshine?</span> \n The answer is: {<span style="color:#fea9d2">summer|park|desktop|sea|moon</span>}</p>
</blockquote></div><div><blockquote>
<p><span style="color:#d3ff9e">Effect: I coughed.</span> \n {<span style="color:#fea9d2">Cause: I inhaled smoke.|Cause: I lowered my voice.</span>}<br>
<span style="color:#d3ff9e">I coughed</span> because {<span style="color:#fea9d2">I inhaled smoke.|I lowered my voice.</span>}</p>
</blockquote></div><div><p>As for the results: the use of special templates did not really make a difference in these experiments, and in some cases the performance even decreased:</p></div><div><p></p><div alt="Results of experiments with special templates, Figure 6 in the paper" src="pasted-image-20240306190502.png" class="internal-embed media-embed image-embed is-loaded"><figure class="image-captions-figure"><img alt="Results of experiments with special templates, Figure 6 in the paper" src="pasted-image-20240306190502.png"><figcaption class="image-captions-caption">Results of experiments with special templates, Figure 6 in the paper</figcaption></figure></div><p></p></div><div><p>Another paper<sup data-footnote-id="fnref-3-4f555327d975d61d" class="footnote-ref" id="fnref-3-4f555327d975d61d"><a href="#fn-3-4f555327d975d61d" class="footnote-link" target="_self" rel="noopener">[3]</a></sup> that came out just this year actually focused on the question of what templates work best. They came to the conclusion that it really depends on the entire setup including the data, model, and examples - so it seems to be a very delicate and complex issue. If that is true, the experiment results here make a lot of sense, because they are averaged over examples and datasets.</p></div><div><p>So, according to these experiments, ICL seems to work even with fewer examples that have completely wrong labels and have little structure apart from simple concatenation of inputs and outputs. Which brings us to the question...</p></div></div></div></div></div><div class="heading-wrapper"><h3 data-heading="What makes ICL work then?" class="heading" id="What_makes_ICL_work_then?"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>What makes ICL work then?</h3><div class="heading-children"><div><p>If the examples don't have the correct labels but still help improve performance, there must be something else that the models can extract from them. The authors of the paper identified four elements that examples in an ICL setting contain:</p></div><div><div data-callout-metadata="" data-callout-fold="" data-callout="basic" class="callout"><div class="callout-title"><div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-star"><polygon points="12 2 15.09 8.26 22 9.27 17 14.14 18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26 12 2"></polygon></svg></div><div class="callout-title-inner">Information in ICL examples</div></div><div class="callout-content">
<ol>
<li data-line="1">input-label mapping</li>
<li data-line="2">distribution of input text</li>
<li data-line="3">label space</li>
<li data-line="4">format</li>
</ol>
</div></div></div><div><p>The first one, input-label mapping, is the only aspect that had been removed in the experiments with the random/wrong labels. As for the other three, the paper presents - you guessed it! - more experiments to see which of them are actually needed to make ICL work.</p></div><div class="heading-wrapper"><h5 data-heading="Distribution of input text" class="heading" id="Distribution_of_input_text"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Distribution of input text</h5><div class="heading-children"><div><p>First up is the distribution of input text, meaning: what typical inputs from the dataset look like.<br>
<br>
To see how important this is, the authors conducted experiments where they used example inputs from a different corpus (<span style="color:#a39bd9">out-of-distribution</span> demos) than the final input/question for which the model is asked to choose a label.</p></div><div><p></p><div alt="Results of experiments with out-of-distribution inputs, Figure 8 in the paper" src="signal-2024-03-06-191542_002.png" class="internal-embed media-embed image-embed is-loaded"><figure class="image-captions-figure"><img alt="Results of experiments with out-of-distribution inputs, Figure 8 in the paper" src="signal-2024-03-06-191542_002.png"><figcaption class="image-captions-caption">Results of experiments with out-of-distribution inputs, Figure 8 in the paper</figcaption></figure></div><p></p></div><div><p>The out-of-distribution examples lead to noticeably weaker performance, with the exception of direct inference with the MetaICL model.  </p></div></div></div><div class="heading-wrapper"><h5 data-heading="Label space" class="heading" id="Label_space"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Label space</h5><div class="heading-children"><div><p>Similarly to how the examples show typical inputs for a task, they also show typical labels. To study the impact of this, the next experiment used <span style="color:#8dd3c7">random English words</span> instead of the actual labels. There are two levels of randomization here: the words are randomly sampled, assigned to the original labels and then randomly matched with inputs.</p></div><div><p></p><div alt="Results of experiments with random words as labels, Figure 9 in the paper" src="signal-2024-03-06-192511_002.png" class="internal-embed media-embed image-embed is-loaded"><figure class="image-captions-figure"><img alt="Results of experiments with random words as labels, Figure 9 in the paper" src="signal-2024-03-06-192511_002.png"><figcaption class="image-captions-caption">Results of experiments with random words as labels, Figure 9 in the paper</figcaption></figure></div><p></p></div><div><p>Apparently, there is a clear difference in trends between inference methods. For direct inference, there is a big performance drop, so having the correct label space represented in the examples seems to be very important for this type of inference. For the channel inference, the impact is much smaller. According to the authors, this is probably because this method only uses the labels for conditioning - so the model doesn't have to estimate the conditional probability of a label that it hasn't seen. </p></div></div></div><div class="heading-wrapper"><h5 data-heading="Format" class="heading" id="Format"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Format</h5><div class="heading-children"><div><p>The most basic aspect of the examples is simply the fact that they are pairs of inputs and outputs. This is what is meant by the format. The variations used to look into whether this format is important for ICL performance were examples that left out either the <span style="color:#7570b3">inputs</span> or the <span style="color:#1b9e77">labels</span>.</p></div><div><p>The aim here was to see how using only inputs or only labels in the demonstrations compares to using both components, with the only difference being the format itself. Things like the input distribution or the label space are additional information separate to the format itself, so the most interesting comparisons here - apart from the baseline without examples - are how using <span style="color:#7570b3">no inputs</span> compares to using <span style="color:#a39bd9">OOD inputs</span>, and how using <span style="color:#1b9e77">no labels</span> compares to using <span style="color:#8dd3c7">random words as labels</span>.</p></div><div><p></p><div alt="Results of experiments with incomplete format, Figure 9 in the paper" src="signal-2024-03-06-195504.png" class="internal-embed media-embed image-embed is-loaded"><figure class="image-captions-figure"><img alt="Results of experiments with incomplete format, Figure 9 in the paper" src="signal-2024-03-06-195504.png"><figcaption class="image-captions-caption">Results of experiments with incomplete format, Figure 9 in the paper</figcaption></figure></div><p></p></div><div><p>With both variants (no inputs and no labels), we see much weaker performance overall. Especially in the classification tasks (upper part of the figure), the format seems to make a large difference in settings where having OOD inputs or random words as labels achieved good performance. It looks like <strong>the format is very important</strong>!</p></div></div></div></div></div><div class="heading-wrapper"><h3 data-heading="Recap and Discussion" class="heading" id="Recap_and_Discussion"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Recap and Discussion</h3><div class="heading-children"><div><div data-callout-metadata="" data-callout-fold="" data-callout="basic" class="callout"><div class="callout-title"><div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-star"><polygon points="12 2 15.09 8.26 22 9.27 17 14.14 18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26 12 2"></polygon></svg></div><div class="callout-title-inner">Part 1: Main results</div></div><div class="callout-content">
<ol>
<li data-line="1">specifying the input and label spaces is what's most important for better<br>
performance using ICL</li>
<li data-line="3">having only the right input distribution or label set still improves performance,<br>
as long as the format is right</li>
<li data-line="5">all of the trends were especially strong for the MetaICL model, which was fine-tuned<br>
for in-context learning</li>
</ol>
</div></div></div><div><p>These results have some pretty cool implications - for instance, if we only need the right input distribution and format to do in-context learning, then we can do it with unlabeled data too! </p></div><div><p>In a simpler (maybe also: more boring) world, this would be it - hooray, we don't need ground truth labels for in-context learning. But we obviously want to be diligent and honest when doing our research. That includes being aware and transparent about limitations. In this case, the authors mention the following:</p></div><div><ol>
<li data-line="0">they only used datasets with natural language inputs</li>
<li data-line="1">they macro-averaged over all datasets</li>
<li data-line="2">they focused on classification and multi-choice tasks only</li>
</ol></div><div><p>This brings us to...</p></div><div><hr></div></div></div></div></div><div class="heading-wrapper"><h2 data-heading="Part 2: &quot;Ground Truth Labels Matter&quot;" class="heading" id="Part_2:_&quot;Ground_Truth_Labels_Matter&quot;"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Part 2: "Ground Truth Labels Matter"</h2><div class="heading-children"><div><p>The paper we've seen in the first part presented a result with quite bold implications - namely that using examples with correct labels isn't that important when doing in-context learning. There were also multiple limitations that the authors admitted - which brings us to the second paper I'd like to show you.</p></div><div><p>While doing my research on the first paper and browsing newer papers that cited it, this one in particular jumped out to me, because the title already made it clear that it is a direct response to the original paper: <em>"Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations"</em><sup data-footnote-id="fnref-4-4f555327d975d61d" class="footnote-ref" id="fnref-4-4f555327d975d61d"><a href="#fn-4-4f555327d975d61d" class="footnote-link" target="_self" rel="noopener">[4]</a></sup>.<br>
They mentioned two main limitations of the first paper:</p></div><div><ol>
<li data-line="0">the averaging across datasets</li>
<li data-line="1">the fact that apart from the general performance measures, there was no quantification of the impact that (not) using ground-truth labels had</li>
</ol></div><div><p>To address this, the authors of this second paper came up with two new metrics and replicated all the experiments in the first paper with an improved setup.</p></div><div><p>The two newly introduced measures are:</p></div><div><div data-callout-metadata="" data-callout-fold="" data-callout="basic" class="callout"><div class="callout-title"><div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-star"><polygon points="12 2 15.09 8.26 22 9.27 17 14.14 18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26 12 2"></polygon></svg></div><div class="callout-title-inner">Label-correctness sensitivity</div></div><div class="callout-content">
<p>This measure expresses how much the performance changes with a certain amount of labels being corrupted - basically: the coefficient of the linear regression that relates the performance measure to the percentage of correctly labelled examples.</p>
</div></div></div><div><div data-callout-metadata="" data-callout-fold="" data-callout="basic" class="callout"><div class="callout-title"><div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-star"><polygon points="12 2 15.09 8.26 22 9.27 17 14.14 18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26 12 2"></polygon></svg></div><div class="callout-title-inner">Ground-truth label effect ratio (GLER)</div></div><div class="callout-content">
<p>This metric is best expressed as:<br>
<span class="math math-block is-loaded"><mjx-container class="MathJax" jax="CHTML" display="true"><mjx-math display="true" class="MJX-TEX" style="margin-left: 0px; margin-right: 0px;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43A TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43F TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D445 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mrow><mjx-mtext class="mjx-n"><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mrow><mjx-mtext class="mjx-n"><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c2D"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c65"></mjx-c></mjx-mtext></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container></span></p>
</div></div></div><div class="heading-wrapper"><h4 data-heading="Results and ablations" class="heading" id="Results_and_ablations"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Results and ablations</h4><div class="heading-children"><div><p>We've already looked at many experiments and many graphs, so I'm just going to quickly summarize the main results.</p></div><div><p>The average label-correctness sensitivity was 0.309 - which means that for each percentage of incorrect labels in examples, the performance measure dropped 0.309%. So for 100% incorrect labels, this result would imply that performance would drop about 30%!<br>
This number also varies a lot across datasets/tasks, so once again, there seem to be other factors at play. One of those factors seems to be task difficulty, which is also analyzed in the paper - in short, low sensitivity is apparently related to low performance in general. Additionally, noisy channel inference reduces sensitivity, while the number of examples and model size lead to an increase.</p></div><div><p>Finally, they also did some more ablations, with one being especially interesting:</p></div><div class="heading-wrapper"><h5 data-heading="Prior-free labels" class="heading" id="Prior-free_labels"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Prior-free labels</h5><div class="heading-children"><div><p>If you think (or scroll ðŸ˜Ž) back to the 4 aspects represented in ICL examples, there are two that involve the labels: the input-label mapping and the label space. There was one experiment in the first paper where the labels were replaced with random English words in such a way that not only was the set of labels a bunch of random words, but those new labels were also randomly assigned to inputs. But what if the original labels were mapped to random words and simply replaced without randomizing? In other words, what if the input-label mapping was preserved with other labels?</p></div><div><p>This is what the authors of the second paper tried to answer with an experiment using <strong>prior-free</strong> labels, meaning labels that don't contain any information about what they mean (e.g. "Positive", "Hate"). Their results indicate that using these kinds of labels does lead to better performance than random mappings, especially when using simple letters or numbers.</p></div><div></div><div><p>All in all:</p></div><div><div data-callout-metadata="" data-callout-fold="" data-callout="basic" class="callout"><div class="callout-title"><div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-star"><polygon points="12 2 15.09 8.26 22 9.27 17 14.14 18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26 12 2"></polygon></svg></div><div class="callout-title-inner">Part 2: Main result</div></div><div class="callout-content">
<p>having the correct input-label mappings does make a performance difference, on some datasets more than on others</p>
</div></div></div><div><hr></div></div></div></div></div></div></div><div class="heading-wrapper"><h2 data-heading="Recap" class="heading" id="Recap"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Recap</h2><div class="heading-children"><div><p>Let's recap: input-label mappings do seem to matter for ICL demonstrations - <strong>but</strong> not always as much as one would think. Also: there is a lot more that goes into in-context learning than just showing a model how inputs relate to outputs. There's many more factors, both on the example level, like the input/label spaces and the format, and in terms of the broader setup, like the model size, model meta-training, dataset, or inference method. In a sense, <strong>it depends on the context</strong>.</p></div><div><p>The papers are two years old as this is being written, so there is already a lot of new research on how to do in-context learning and why it works. Here are some more interesting papers I found, if you are motivated to do more reading:</p></div><div><ul>
<li data-line="0"><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2303.03846" rel="noopener" class="external-link" href="https://arxiv.org/abs/2303.03846" target="_blank">how larger models perform with incorrect or prior-free labels</a><sup data-footnote-id="fnref-5-4f555327d975d61d" class="footnote-ref" id="fnref-5-4f555327d975d61d"><a href="#fn-5-4f555327d975d61d" class="footnote-link" target="_self" rel="noopener">[5]</a></sup></li>
<li data-line="1"><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2301.00234" rel="noopener" class="external-link" href="https://arxiv.org/abs/2301.00234" target="_blank">a survey about ICL in general from 2023</a><sup data-footnote-id="fnref-6-4f555327d975d61d" class="footnote-ref" id="fnref-6-4f555327d975d61d"><a href="#fn-6-4f555327d975d61d" class="footnote-link" target="_self" rel="noopener">[6]</a></sup></li>
<li data-line="2"><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2401.11624" rel="noopener" class="external-link" href="https://arxiv.org/abs/2401.11624" target="_blank">a survey about using retrieved demonstrations in ICL, i.e. choosing specific demonstrations for an input</a><sup data-footnote-id="fnref-7-4f555327d975d61d" class="footnote-ref" id="fnref-7-4f555327d975d61d"><a href="#fn-7-4f555327d975d61d" class="footnote-link" target="_self" rel="noopener">[7]</a></sup></li>
<li data-line="3"><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2305.01639" rel="noopener" class="external-link" href="https://arxiv.org/abs/2305.01639" target="_blank">a paper about privacy in ICL</a><sup data-footnote-id="fnref-8-4f555327d975d61d" class="footnote-ref" id="fnref-8-4f555327d975d61d"><a href="#fn-8-4f555327d975d61d" class="footnote-link" target="_self" rel="noopener">[8]</a></sup></li>
</ul></div><div><p>I hope you've learned a thing or two about in-context learning and understood the main ideas from the two papers.</p></div><div><hr></div></div></div><div class="heading-wrapper"><h2 data-heading="References" class="heading" id="References"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>References</h2><div class="heading-children"><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div>
</div><div><section class="footnotes"><hr><ol>
<li data-line="-7" data-footnote-id="fn-1-4f555327d975d61d" id="fn-1-4f555327d975d61d">Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., &amp; Zettlemoyer, L. (2022a). Rethinking the role of demonstrations: What makes in-context learning work?&nbsp;<em>arXiv Preprint arXiv:2202.12837</em>.&nbsp;<a rel="noopener" class="external-link" href="https://arxiv.org/abs/2202.12837" target="_blank">https://arxiv.org/abs/2202.12837</a><a href="#fnref-1-4f555327d975d61d" class="footnote-backref footnote-link" target="_self" rel="noopener">â†©ï¸Ž</a></li>
<li data-line="-6" data-footnote-id="fn-2-4f555327d975d61d" id="fn-2-4f555327d975d61d">Min, S., Lewis, M., Hajishirzi, H., &amp; Zettlemoyer, L. (2022). Noisy channel language model prompting for few-shot text classification.&nbsp;<em>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics Volume 1: Long Papers</em>, 5316â€“5330.&nbsp;<a rel="noopener" class="external-link" href="https://aclanthology.org/2022.acl-long.365.pdf" target="_blank">https://aclanthology.org/2022.acl-long.365.pdf</a><a href="#fnref-2-4f555327d975d61d" class="footnote-backref footnote-link" target="_self" rel="noopener">â†©ï¸Ž</a></li>
<li data-line="-4" data-footnote-id="fn-3-4f555327d975d61d" id="fn-3-4f555327d975d61d">Voronov, A., Wolf, L., &amp; Ryabinin, M. (2024).&nbsp;<em>Mind your format: Towards consistent evaluation of in-context learning improvements</em>.&nbsp;<a rel="noopener" class="external-link" href="https://arxiv.org/abs/2401.06766" target="_blank">https://arxiv.org/abs/2401.06766</a><a href="#fnref-3-4f555327d975d61d" class="footnote-backref footnote-link" target="_self" rel="noopener">â†©ï¸Ž</a></li>
<li data-line="-5" data-footnote-id="fn-4-4f555327d975d61d" id="fn-4-4f555327d975d61d">Yoo, K. M., Kim, J., Kim, H. J., Cho, H., Jo, H., Lee, S.-W., Lee, S., &amp; Kim, T. (2022).&nbsp;<em>Ground-truth labels matter: A deeper look into input-label demonstrations</em>.&nbsp;<a rel="noopener" class="external-link" href="https://arxiv.org/abs/2205.12685" target="_blank">https://arxiv.org/abs/2205.12685</a><a href="#fnref-4-4f555327d975d61d" class="footnote-backref footnote-link" target="_self" rel="noopener">â†©ï¸Ž</a></li>
<li data-line="0" data-footnote-id="fn-5-4f555327d975d61d" id="fn-5-4f555327d975d61d">Wei, J., Wei, J., Tay, Y., Tran, D., Webson, A., Lu, Y., Chen, X., Liu, H., Huang, D., Zhou, D., &amp; others. (2023). Larger language models do in-context learning differently.&nbsp;<em>arXiv Preprint arXiv:2303.03846</em>. <a rel="noopener" class="external-link" href="https://arxiv.org/abs/2303.03846" target="_blank">https://arxiv.org/abs/2303.03846</a><a href="#fnref-5-4f555327d975d61d" class="footnote-backref footnote-link" target="_self" rel="noopener">â†©ï¸Ž</a></li>
<li data-line="-3" data-footnote-id="fn-6-4f555327d975d61d" id="fn-6-4f555327d975d61d">Dong, Q., Li, L., Dai, D., Zheng, C., Wu, Z., Chang, B., Sun, X., Xu, J., Li, L., &amp; Sui, Z. (2023).&nbsp;<em>A survey on in-context learning</em>.&nbsp;<a rel="noopener" class="external-link" href="https://arxiv.org/abs/2301.00234" target="_blank">https://arxiv.org/abs/2301.00234</a><a href="#fnref-6-4f555327d975d61d" class="footnote-backref footnote-link" target="_self" rel="noopener">â†©ï¸Ž</a></li>
<li data-line="-2" data-footnote-id="fn-7-4f555327d975d61d" id="fn-7-4f555327d975d61d">Xu, X., Liu, Y., Pasupat, P., Kazemi, M., &amp; others. (2024). In-context learning with retrieved demonstrations for language models: A survey.&nbsp;<em>arXiv Preprint arXiv:2401.11624</em>. <a rel="noopener" class="external-link" href="https://arxiv.org/abs/2401.11624" target="_blank">https://arxiv.org/abs/2401.11624</a><a href="#fnref-7-4f555327d975d61d" class="footnote-backref footnote-link" target="_self" rel="noopener">â†©ï¸Ž</a></li>
<li data-line="-1" data-footnote-id="fn-8-4f555327d975d61d" id="fn-8-4f555327d975d61d">Panda, A., Wu, T., Wang, J. T., &amp; Mittal, P. (2023). Differentially private in-context learning.&nbsp;<em>arXiv Preprint arXiv:2305.01639</em>. <a rel="noopener" class="external-link" href="https://arxiv.org/abs/2305.01639" target="_blank">https://arxiv.org/abs/2305.01639</a><a href="#fnref-8-4f555327d975d61d" class="footnote-backref footnote-link" target="_self" rel="noopener">â†©ï¸Ž</a></li>
</ol></section></div><div class="mod-footer"></div></div></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="blogpost.html#Ground Truth <em>Kinda</em> Matters - About the In's and Out's of In-Context Learning"><div class="tree-item-contents heading-link" heading-name="Ground Truth Kinda Matters - About the In's and Out's of In-Context Learning"><span class="tree-item-title">Ground Truth Kinda Matters - About the In's and Out's of In-Context Learning</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="blogpost.html#Introduction:_In-context_learning"><div class="tree-item-contents heading-link" heading-name="Introduction: In-context learning"><span class="tree-item-title">Introduction: In-context learning</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="blogpost.html#Part_1:_&quot;Ground_Truth_Matters_Little&quot;"><div class="tree-item-contents heading-link" heading-name="Part 1: &quot;Ground Truth Matters Little&quot;"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Part 1: "Ground Truth Matters Little"</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-link" href="blogpost.html#Details_about_the_experiments"><div class="tree-item-contents heading-link" heading-name="Details about the experiments"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Details about the experiments</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="4"><a class="tree-link" href="blogpost.html#Models"><div class="tree-item-contents heading-link" heading-name="Models"><span class="tree-item-title">Models</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="blogpost.html#Datasets"><div class="tree-item-contents heading-link" heading-name="Datasets"><span class="tree-item-title">Datasets</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="4"><a class="tree-link" href="blogpost.html#Procedure"><div class="tree-item-contents heading-link" heading-name="Procedure"><span class="tree-item-title">Procedure</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="blogpost.html#Gold_labels_vs_random_labels"><div class="tree-item-contents heading-link" heading-name="Gold labels vs random labels"><span class="tree-item-title">Gold labels vs random labels</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-link" href="blogpost.html#What_does_not_matter_for_ICL?"><div class="tree-item-contents heading-link" heading-name="What does not matter for ICL?"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">What does not matter for ICL?</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="5"><a class="tree-link" href="blogpost.html#1._Does_it_matter_*how_many*_correct_labels_are_used?"><div class="tree-item-contents heading-link" heading-name="1. Does it matter *how many* correct labels are used?"><span class="tree-item-title">1. 
Does it matter how many correct labels are used?
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="5"><a class="tree-link" href="blogpost.html#2._Does_the_number_of_examples_matter?"><div class="tree-item-contents heading-link" heading-name="2. Does the number of examples matter?"><span class="tree-item-title">2. 
Does the number of examples matter?
</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="5"><a class="tree-link" href="blogpost.html#3._Does_the_way_in_which_the_examples_are_presented_matter?"><div class="tree-item-contents heading-link" heading-name="3. Does the way in which the examples are presented matter?"><span class="tree-item-title">3. 
Does the way in which the examples are presented matter?
</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="3"><a class="tree-link" href="blogpost.html#What_makes_ICL_work_then?"><div class="tree-item-contents heading-link" heading-name="What makes ICL work then?"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">What makes ICL work then?</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="5"><a class="tree-link" href="blogpost.html#Distribution_of_input_text"><div class="tree-item-contents heading-link" heading-name="Distribution of input text"><span class="tree-item-title">Distribution of input text</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="5"><a class="tree-link" href="blogpost.html#Label_space"><div class="tree-item-contents heading-link" heading-name="Label space"><span class="tree-item-title">Label space</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="5"><a class="tree-link" href="blogpost.html#Format"><div class="tree-item-contents heading-link" heading-name="Format"><span class="tree-item-title">Format</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="3"><a class="tree-link" href="blogpost.html#Recap_and_Discussion"><div class="tree-item-contents heading-link" heading-name="Recap and Discussion"><span class="tree-item-title">Recap and Discussion</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-link" href="blogpost.html#Part_2:_&quot;Ground_Truth_Labels_Matter&quot;"><div class="tree-item-contents heading-link" heading-name="Part 2: &quot;Ground Truth Labels Matter&quot;"><div class="collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Part 2: "Ground Truth Labels Matter"</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="4"><a class="tree-link" href="blogpost.html#Results_and_ablations"><div class="tree-item-contents heading-link" heading-name="Results and ablations"><span class="tree-item-title">Results and ablations</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="5"><a class="tree-link" href="blogpost.html#Prior-free_labels"><div class="tree-item-contents heading-link" heading-name="Prior-free labels"><span class="tree-item-title">Prior-free labels</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="blogpost.html#Recap"><div class="tree-item-contents heading-link" heading-name="Recap"><span class="tree-item-title">Recap</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="blogpost.html#References"><div class="tree-item-contents heading-link" heading-name="References"><span class="tree-item-title">References</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>